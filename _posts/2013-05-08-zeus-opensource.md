---
layout: blog
excerpt: 一个完善的Hadoop作业平台
---

###宙斯开源了  

宙斯开源了，地址在：<a href="https://github.com/alibaba/zeus" target="_blank">https://github.com/alibaba/zeus</a>  
这个系统做了一年多，现在开源了，也算是一个里程碑吧  


这个系统做了一年多，这几乎是一个完完全全由我打造的产品  
没有产品经理，没有测试，没有视觉交互设计师，没有前端开发  
只有我一个人，包揽了这个产品的所有角色。 (后期加入了<a href="https://github.com/abop" target="_blank">古飞</a>，参与一起开发)  
也正是因为这个，你才能看到那几个彰显屌丝身份的图标  

2011年初，关联推荐团队开始组建，我负责搭建推荐系统  
一期项目完工后，我们开始陆续接入业务  
作为淘宝最早的一个推荐团队，我们逐步接入了大量的业务场景。  
同时为了提升场景的推荐效果，我们在系统层面又支持了A/B测试  
也就是说在一个场景背后，可能有N种算法在进行比较验算，通过不断的迭代来提升效果  

如此算来，我们的算法越来越多了，完全无法用人工的方法来维护这些算法。  
而且大部分都是每天都在跑的，万一某个算法跑失败了，我们也需要一个报警渠道  

因此在2011年的下半年里，我们部门开始尝试搭建一个管理和调度所有算法的一个平台，取名宙斯。  

----------------

最早版本的宙斯，我并没有参与，是我的同事苍擎一手搭建起来的。  

第一版的宙斯参考了开源项目 <a href="https://github.com/azkaban/azkaban" target="_blank">azkaban</a> ，使用过程中发现了一个比较严重的调度依赖问题。  
假设如下图所示的一个依赖关系图。  

<a href="/assets/images/articles/zeus/graph-schedule.png" target="_blank"><img src="/assets/images/articles/zeus/graph-dependency.png"/></a>

在老版宙斯中的处理逻辑是自下而上的。  
我们需要为所有的任务设定一个触发时间，比如每天凌晨3点  
假设 ***业务job1*** 在凌晨3点触发了，调度系统会以递归的方式去查找依赖job，这里就是 ***加工job1*** ，然后触发 ***加工job1*** 启动。  
同理 ***加工job1*** 又会触发 ***基础job1***  

这种依赖调度的处理方式会存在一些问题：  
1.重复调度  
  ***业务job1***  和  ***业务job2*** 分别触发，会导致底层的公共job被反复调度，浪费资源，并发情况下还会有异常  
2.实时性差  
  每一个job都需要事先设定一个调度周期，不能充分利用实时性  
  比如 ***基础job1*** 在凌晨1点就运行完了，我们会希望 ***加工job1*** 在依赖任务完成时马上启动。但是这种调度方式无法满足  
  
基于以上一些问题的考虑，我们打算重写一下宙斯，把底层的一些问题解决掉。同时也希望在可视化操作方面能够改进一下，给用户一个更好的体验。  

而这个新版本的宙斯则是由我来接手搭建了。  

------

2012年过完春节，新版宙斯项目准备开工，而我兼任 产品经理，开发，测试，视觉，UED，一个屌丝的项目就正式开始了  

###调度内核  
新版宙斯第一个需要解决的问题就是依赖调度的问题，这个问题是调度系统最基础也是最核心的问题。  
我希望把调度设计的简单而强大。而且我觉得简单比强大更重要。一个好的系统，在内行人看来应该是一个简单的系统。如果内行人都觉得复杂，那就说明这个系统设计的不够好了  
最后我们的调度设计如下图所示，任务的执行变成从上往下了。  

<a href="/assets/images/articles/zeus/graph-schedule.png" target="_blank"><img src="/assets/images/articles/zeus/graph-schedule.png"/></a>  

###分布式设计  
依赖调度问题解决后，下一个需要考虑的就是分布式设计了。随着业务的发展，单服务器必然是不够的，我希望能够做到真正的水平扩展。  
最早的版本，我临时采用了公司内部的HSF服务，来进行Scheduler与Worker直接的通信。比如Scheduler向Worker派发一个任务。  
但显然HSF不是一个合适的框架，我们需要一个能够在Scheduler与Worker之间进行灵活通信的框架。Scheduler可以向Worker分配任务，取消任务。Worker也可以主动向Scheduler发送心跳  
最终我决定采用netty自己写一个简单的通信协议  
最终，我们的分布式调度可以实现以下功能：  
1.水平扩展  
>不区分Scheduler和Worker和Web，新服务器启动web容器即可  

2.心跳监控  
>Worker会定期向Scheduler发送心跳，包含Worker服务器自身的状态，比如正在运行的任务，时间戳，服务器的内存占用率，CPU使用率等  

3.负载均衡  
>Scheduler会根据Worker反馈的心跳信息来分配任务，比如Worker内存占用率超过80%即不再分配。如果所有的Worker都满负荷运行，则将任务放入队列，等到有空闲Worker了再分配  

###开发中心  
到目前为止，我们基本完成的一个调度系统应该有的功能。也基本上满足了部门业务的需求。  
但是从更广的视野上观察，我们觉得还缺少很重要的一个步骤，那就是开发阶段。  
一个完整的任务周期应该是：调试开发阶段->测试阶段->上线调度阶段  
而现有的系统只是解决了最后一个阶段的工作，我希望在宙斯平台能够包含任务的整个生命周期。  
于是我计划开发一个开发中心，将调试开发阶段和测试阶段也包含进来。  
也就是在这个时候，宙斯系统加入了一个新的开发：古飞  
完工后的开发中心，基本实现了以上的需求。开发中心同时也还是一个文档管理中心，随着脚本越来越多，在开发中心你分组分层次的对文档进行管理。同时还可以共享文档，让其他同事也能看到。  



###Hive的可视化  
早期的算法，我们采用的MapReduce，但是后续随着hive的引入，大部分算法开始转移到hive中去了。毕竟写sql的效率要远远高于写Java代码  
随着hive使用量的增加，越来越多的人对hive信息的可视化需求增加  
他们希望能够查询有哪些表，结构如何，有哪些分区，数据是否可以预览等等  
因此我们在开发中心添加了Hive可视化的支持，在任务的调试开发阶段给用户提供了很大的便利  
这里Hive可视化大部分工作都是由古飞完成的  

###用户体验的持续改进  
整个宙斯系统，我一直认为我们的核心竞争力不是技术，而是用户体验  
我觉得我们的技术一点都不牛逼，和大家说个原理，相信大家都觉得简单。  

宙斯系统做了一年左右，核心的几个技术问题，其实在3个月左右的时间里就解决了。  
后续打大半年时间里，我们都把大量精力放在了用户体验的工作上  
宙斯系统屏蔽了技术细节，用户不需要自己的服务器，不关心背后的分布式设计，负载均衡。  
用户只需要携脚本入驻即可  
我们尽最大可能，让产品变得简单，容易上手  
每次添加新功能，我们都需要考虑如何合理的嵌入现有系统，避免功能叠加导致的产品变复杂  
我们对产品界面交互多次改版，让系统交互更加合理与简单  


我们甚至对运维都十分友好   
整个宙斯系统就是一个web应用，这个应用里包含了web，scheduler，worker。  
单台服务器就启动一个web应用，分布式就启动多个web应用  
不需要区分多种服务器类型，不需要分别部署维护  


###关于开源  
宙斯开源了，非常欢迎有需求的人来使用这个产品  
如果这个开源产品没什么人来用，相信我也没法有很大的激情持续去维护更新。  
因此，如果你喜欢这个产品，支持这个产品，欢迎你来宙斯提<a href="https://github.com/alibaba/zeus/issues?state=open" target="_blank">issue</a>  
你的提问，就是我的动力  


